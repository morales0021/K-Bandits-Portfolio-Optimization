{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe0e652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mora/Documents/projects/Bandits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "path = '/'.join(os.path.abspath('').split('/')[0:-2])\n",
    "print(path)\n",
    "sys.path.append(path)\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import random, tqdm\n",
    "import numpy as np\n",
    "\n",
    "from experts.alpha import alpha\n",
    "from exploration.explore import explore\n",
    "from exploration.outils import stats\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6169ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../datasharing/tickers.json','r') as file:\n",
    "    tickers = json.load(file)\n",
    "\n",
    "tickers = tickers[\"sp500\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db77b0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_194788/1425304769.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_close_stocks['date'] = df_close_stocks.index\n",
      "/tmp/ipykernel_194788/1425304769.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_close_stocks.reset_index(inplace = True)\n",
      "/tmp/ipykernel_194788/1425304769.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_close_stocks['date'] = pd.to_datetime(df_close_stocks['Date'])\n"
     ]
    }
   ],
   "source": [
    "# Load the pickle file that contains the full data for each stock\n",
    "with open('../../../datasharing/hist_stock_data.pkl','rb') as file:\n",
    "    df_hst_tickers = pickle.load(file)\n",
    "\n",
    "# Chose the label \"Close\" as the main label to analyse the price series\n",
    "label = 'Close'\n",
    "df_close_stocks = pd.DataFrame([])\n",
    "for key, df in df_hst_tickers.items():\n",
    "    df_close_stocks = pd.concat([df_close_stocks,\n",
    "                                 df[label]], axis = 1)\n",
    "\n",
    "# Create a single data frame that cotains the series data from all the SP500 stocks\n",
    "df_close_stocks.columns = list(df_hst_tickers.keys())\n",
    "df_close_stocks['date'] = df_close_stocks.index\n",
    "df_close_stocks.index = pd.to_datetime(df_close_stocks['date'])\n",
    "\n",
    "\n",
    "df_close_stocks = pd.DataFrame()\n",
    "\n",
    "for ticker in tickers:\n",
    "    srs = df_hst_tickers[ticker][['Close']]\n",
    "    srs.columns = [ticker]\n",
    "    df_close_stocks = pd.concat([df_close_stocks,srs], axis = 1)\n",
    "    \n",
    "df_close_stocks.reset_index(inplace = True)\n",
    "df_close_stocks['date'] = pd.to_datetime(df_close_stocks['Date'])\n",
    "\n",
    "df_close_stocks.set_index('date', inplace = True)\n",
    "df_2w = df_close_stocks.resample(\"2W\").last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d26a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the function that compute the statistics\n",
    "def get_stats(df_close_stocks, tickers, years = None, inter = None, freq = 'M', min_els = 6):\n",
    "    \"\"\"\n",
    "    This function produces some statistics using a dataframe fille with stocks.\n",
    "    Precisely the average mean return and the sharpe ratio.\n",
    "    Args:\n",
    "        df_hst_tickers (dict) - contains dataframes for multiple stocks\n",
    "        tickers (list) - the list of tickers to compute the statistics \n",
    "        years (list) - the list of years to compute the statistics\n",
    "        inter (slice) - A slice that precises the data indexs to compute the statistics\n",
    "        freq (str) - the frequency for the statistics (Y,M,W,2W, ...)\n",
    "        min_els(int) - the minimum quantity of elements in the series required\n",
    "            after the frequency postprocessing.\n",
    "    \"\"\"\n",
    "    st_stats = {}\n",
    "    for ticker in tickers:\n",
    "        if years:\n",
    "            tmp_df = df_close_stocks[df_close_stocks['Date'].dt.year.isin(years)]\n",
    "        elif inter:\n",
    "            tmp_df = df_close_stocks.iloc[inter]\n",
    "\n",
    "        pc_m = tmp_df[ticker].pct_change(periods = 1, freq = freq).dropna()\n",
    "\n",
    "        # discart ticket if not enough data\n",
    "        if pc_m.shape[0] < min_els:\n",
    "            continue\n",
    "            \n",
    "        av_ret = pc_m.mean()\n",
    "        sr = av_ret / pc_m.std()\n",
    "        st_stats[ticker] = {\"sr\":sr, 'av_ret':av_ret}\n",
    "            \n",
    "    return st_stats\n",
    "\n",
    "def df_and_sort(st_stats, col):\n",
    "    \"\"\"\n",
    "    Function that creates a dataframe using a dictionary with of stocks with statistics\n",
    "    metrics and sort the dataframe based on the column name precised.\n",
    "    Args:\n",
    "        st_stats (dict) - The dictionary containing the statistics.\n",
    "        col (str) - The name of the column for sorting.\n",
    "    \"\"\"\n",
    "    df_stats = pd.DataFrame(st_stats).transpose()\n",
    "    df_stats.sort_values(by=col, inplace = True, ascending = False)\n",
    "    return df_stats\n",
    "\n",
    "\n",
    "def create_stock_groups(lst_stocks: list, basket_size: int,\n",
    "                        max_stocks: int):\n",
    "    \"\"\"\n",
    "    Create multiple group of stocks with basket_size elements\n",
    "    inside each group.\n",
    "    Args:\n",
    "        lst_stocks (list) : List of stocks\n",
    "        basket_size (int): The total element of stocks in\n",
    "            each basket.\n",
    "    \"\"\"\n",
    "    \n",
    "    random.shuffle(tst)\n",
    "    stcks = {'stocks_dict':list(tst), 'groups':{}}\n",
    "\n",
    "    for i in range(0,max_stocks,basket_size):\n",
    "        stcks['groups'].update({i:list(tst[i:i+basket_size])})\n",
    "    \n",
    "    return stcks\n",
    "\n",
    "\n",
    "def simulate_year(df_series, years: list, n_sims: int,\n",
    "                  stock_groups: dict, exploration_rate: float,\n",
    "                  p_alpha: float):\n",
    "\n",
    "    df_test = df_series[df_series['Date'].dt.year.isin(years)]\n",
    "    lines = []\n",
    "\n",
    "    for group, lst_stocks in stock_groups['groups'].items():\n",
    "\n",
    "        df_bandits = df_test[lst_stocks].pct_change(1).dropna()\n",
    "\n",
    "        if df_bandits.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        arguments = {\"exploration_rate\": exploration_rate,\n",
    "                     \"n_bandit\":df_bandits.shape[1],\n",
    "                     \"steps\":df_bandits.shape[0],\n",
    "                     \"alpha\":p_alpha,\n",
    "                     \"df_bandits\":df_bandits\n",
    "                    }\n",
    "\n",
    "\n",
    "        exp = explore(alpha.execute)\n",
    "        exp.execute(n_sims, **arguments)\n",
    "        mean, std = stats(exp.rets_compo)\n",
    "        line = [arguments[\"alpha\"],\n",
    "                arguments[\"exploration_rate\"],\n",
    "                mean,\n",
    "                std]\n",
    "\n",
    "        lines.append(line)\n",
    "\n",
    "    df_rets = pd.DataFrame(lines)\n",
    "    df_rets.columns = [\"alpha\", \"expl\", \"mean\", \"std\"]\n",
    "    \n",
    "    return df_rets.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6be7e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 11/11 [00:42<00:00,  3.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create a group of stocks\n",
    "max_stocks = 120\n",
    "stock_groups = {}\n",
    "basket_size = 5\n",
    "metric = 'sr' # choose between 'av_ret' or 'sr'\n",
    "\n",
    "for year in tqdm.tqdm(range(2013,2024)):\n",
    "\n",
    "    years_tr = list(range(year - 10, year))\n",
    "    stats_tr = get_stats(df_close_stocks, tickers, years = years_tr)\n",
    "    df_stats_tr = df_and_sort(stats_tr, metric)\n",
    "    tst = df_stats_tr.index[0:max_stocks].values\n",
    "    stock_groups[year] = create_stock_groups(tickers,\n",
    "                                             basket_size,\n",
    "                                             max_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa51d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████                | 7/11 [05:44<03:16, 49.15s/it]"
     ]
    }
   ],
   "source": [
    "final_stats = []\n",
    "\n",
    "for year in tqdm.tqdm(range(2013,2024)):\n",
    "    for exploration_rate in np.arange(0.01,0.15,0.01):\n",
    "        for p_alpha in np.arange(0.005,0.15,0.005):\n",
    "            st_year = simulate_year(df_2w, [year], n_sims = 5,\n",
    "                                    stock_groups = stock_groups[year],\n",
    "                                    exploration_rate = exploration_rate,\n",
    "                                    p_alpha = p_alpha\n",
    "                                   )\n",
    "            tmp_year = {\"year\":year,\"ex_rate\":exploration_rate,\n",
    "                        \"alpha\":p_alpha, \"return\": st_year['mean']}\n",
    "            final_stats.append(tmp_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59163596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(final_stats)\n",
    "df_groups = df_res.groupby(by=['ex_rate','alpha']).mean()['return'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = '../../../datasharing/df_groups_alpha.csv'\n",
    "df_groups.to_csv(path_csv,index = False)\n",
    "df_groups = pd.read_csv(path_csv)\n",
    "df_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups['return'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(df_groups, x=\"ex_rate\", y=\"alpha\", z=\"return\",\n",
    "                         histfunc=\"avg\"\n",
    "                        )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_rate = 0.01\n",
    "p_alpha = 0.05\n",
    "\n",
    "s_final_state = []\n",
    "for year in tqdm.tqdm(range(2013,2024)):\n",
    "    st_year = simulate_year(df_2w, [year], n_sims = 5,\n",
    "                            stock_groups = stock_groups[year],\n",
    "                            exploration_rate = exploration_rate,\n",
    "                            p_alpha = p_alpha\n",
    "                           )\n",
    "    s_final_state.append(st_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year = pd.DataFrame(s_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_year = df_year['mean'].mean()\n",
    "std_year = df_year['mean'].std()\n",
    "com_ret = (df_year['mean'] + 1).cumprod()\n",
    "com_ret_last = com_ret.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a86582",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean average return per year \", mean_year)\n",
    "print(\"Mean average std per year \", std_year)\n",
    "print(\"Return final year \", com_ret_last)\n",
    "com_ret.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
